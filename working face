// --- DOM Elements (Updated with new elements for preview) ---
const loader = document.getElementById('loader');
const monitorContainer = document.querySelector('.monitor-container');
const liveFeed = document.getElementById('liveFeed');
const canvas = document.getElementById('canvas');
const showPointsToggle = document.getElementById('showPointsToggle');
const logPanel = document.getElementById('log-panel');
const faceList = document.getElementById('faceList');
const downloadDataBtn = document.getElementById('downloadDataBtn');
const importDataInput = document.getElementById('importDataInput');
const saveSettingsBtn = document.getElementById('saveSettingsBtn');
const alertThresholdInput = document.getElementById('alertThresholdInput');

// MODIFIED: This is the critical fix. We now get the new indicator element.
const cameraStatusIndicator = document.getElementById('cameraStatusIndicator');

// --- Registration Elements (Updated with new elements for preview) ---
const openCameraBtn = document.getElementById('openCameraBtn');
const imageUpload = document.getElementById('imageUpload');
const cameraModal = document.getElementById('cameraModal');
const modalVideo = document.getElementById('modal-video');
const modalCanvas = document.getElementById('modal-canvas');
const snapBtn = document.getElementById('snapBtn');
const closeModalBtn = document.getElementById('closeModalBtn');
const analysisContainer = document.getElementById('analysis-container');
const imagePreview = document.getElementById('imagePreview');
const analysisCanvas = document.getElementById('analysisCanvas');
const registrationForm = document.getElementById('registration-form');
const nameInput = document.getElementById('nameInput');
const saveButton = document.getElementById('saveButton');
const cancelButton = document.getElementById('cancelButton');

// --- State Variables ---
let faceDataMap = new Map();
const notifiedNames = new Set();
let faceDescriptorForRegistration = null;
let detectionInterval;
const socket = io();

// --- Socket.IO Communication (MODIFIED) ---
function setupSocketListeners() {
    socket.on('connect', () => {
        console.log('Connected to server as a monitor.');
        socket.emit('join-as-monitor');
    });

    socket.on('update-stream', (data) => {
        liveFeed.src = data;
        // Update the new status indicator
        cameraStatusIndicator.classList.remove('offline');
        cameraStatusIndicator.classList.add('online');
        cameraStatusIndicator.textContent = 'ONLINE';
    });
    
    socket.on('camera-status', (data) => {
        if (data.status === 'offline') {
            cameraStatusIndicator.classList.remove('online');
            cameraStatusIndicator.classList.add('offline');
            cameraStatusIndicator.textContent = 'OFFLINE';
        }
    });

    socket.on('disconnect', () => {
        cameraStatusIndicator.classList.remove('online');
        cameraStatusIndicator.classList.add('offline');
        cameraStatusIndicator.textContent = 'OFFLINE';
    });
}

// --- Face Analysis for Registration (NEW & CORRECTED) ---
async function analyzeAndDisplayFace(imageElement) {
    // 1. Show the preview container and loader
    analysisContainer.style.display = 'block';
    loader.innerText = 'Analyzing face...';
    loader.style.display = 'block';

    // 2. Wait for the image to be fully loaded
    await new Promise(resolve => {
        if (imageElement.complete && imageElement.naturalHeight !== 0) resolve();
        else imageElement.onload = resolve;
    });

    const displaySize = { width: imageElement.width, height: imageElement.height };
    faceapi.matchDimensions(analysisCanvas, displaySize);

    // 3. Perform detection
    const detection = await faceapi.detectSingleFace(imageElement, new faceapi.SsdMobilenetv1Options()).withFaceLandmarks().withFaceDescriptor();
    
    // 4. Hide loader and process results
    loader.style.display = 'none';

    if (detection) {
        const resizedDetection = faceapi.resizeResults(detection, displaySize);
        analysisCanvas.getContext('2d').clearRect(0, 0, analysisCanvas.width, analysisCanvas.height);
        faceapi.draw.drawDetections(analysisCanvas, resizedDetection);
        faceapi.draw.drawFaceLandmarks(analysisCanvas, resizedDetection);
        
        faceDescriptorForRegistration = detection.descriptor;
        registrationForm.style.display = 'block'; // Show the save form
    } else {
        alert('No face detected or face is unclear. Please try another image.');
        resetRegistrationForm(); // Clear everything if no face is found
    }
}

// --- UI & Event Handlers (MODIFIED) ---

// NEW: Registration via File Upload
imageUpload.addEventListener('change', async (event) => {
    if (!event.target.files || event.target.files.length === 0) return;
    const file = event.target.files[0];
    const imageUrl = URL.createObjectURL(file);
    imagePreview.src = imageUrl;
    await analyzeAndDisplayFace(imagePreview);
});

// MODIFIED: Webcam capture now uses the analysis preview flow
async function setupRegistrationCamera() {
    try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
        modalVideo.srcObject = stream;
        await new Promise(resolve => modalVideo.onloadedmetadata = resolve);
        return stream;
    } catch (err) {
        alert('Could not access camera. Please check permissions.');
        return null;
    }
}
openCameraBtn.addEventListener('click', async () => {
    cameraModal.style.display = 'flex';
    const stream = await setupRegistrationCamera();
    if (!stream) cameraModal.style.display = 'none';
});

closeModalBtn.addEventListener('click', () => {
    const stream = modalVideo.srcObject;
    if (stream) stream.getTracks().forEach(track => track.stop());
    modalVideo.srcObject = null;
    cameraModal.style.display = 'none';
});

// THIS IS THE KEY CORRECTION
snapBtn.addEventListener('click', async () => {
    // 1. Capture the current frame to a temporary canvas
    const tempCanvas = document.createElement('canvas');
    tempCanvas.width = modalVideo.videoWidth;
    tempCanvas.height = modalVideo.videoHeight;
    tempCanvas.getContext('2d').drawImage(modalVideo, 0, 0);

    // 2. Set the preview image's source to the captured frame data
    imagePreview.src = tempCanvas.toDataURL('image/jpeg');

    // 3. Close the modal immediately
    closeModalBtn.click();

    // 4. Call the central analysis function on the preview image
    await analyzeAndDisplayFace(imagePreview);
});

// NEW: Function to reset the entire registration UI
function resetRegistrationForm() {
    analysisContainer.style.display = 'none';
    registrationForm.style.display = 'none';
    imagePreview.src = '#';
    if(analysisCanvas) analysisCanvas.getContext('2d').clearRect(0, 0, analysisCanvas.width, analysisCanvas.height);
    nameInput.value = '';
    imageUpload.value = ''; // This allows re-uploading the same file
    faceDescriptorForRegistration = null;
}
cancelButton.addEventListener('click', resetRegistrationForm);

// MODIFIED: Save button now calls the new reset function
saveButton.addEventListener('click', async () => {
    const name = nameInput.value.trim();
    const action = document.querySelector('input[name="action"]:checked').value;
    if (!name || !faceDescriptorForRegistration) {
        alert('Please provide a name and a detected face.');
        return;
    }
    try {
        const response = await fetch('/save', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ name, descriptor: Array.from(faceDescriptorForRegistration), action })
        });
        const result = await response.json();
        if (response.ok) {
            alert('Person saved successfully!');
            resetRegistrationForm();
            await fetchAndDisplayFaces();
            await startDetection();
        } else {
            alert('Error: ' + result.error);
        }
    } catch (error) {
        console.error('Error saving face:', error);
    }
});


// --- Core Logic & Initialization (Copied from your working version, unchanged) ---
async function loadModels() {
    const MODEL_URL = '/models';
    loader.innerText = 'Loading Core Models...';
    await Promise.all([
        faceapi.nets.ssdMobilenetv1.loadFromUri(MODEL_URL),
        faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),
        faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),
        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL)
    ]);
}

async function getLabeledFaceDescriptions() {
    try {
        const response = await fetch('/faces');
        const faces = await response.json();
        if (faces.length === 0) return null;
        faceDataMap = new Map(faces.map(f => [f.name, f]));
        return faces.map(face => new faceapi.LabeledFaceDescriptors(face.name, [new Float32Array(face.descriptor)]));
    } catch (error) {
        console.error("Could not fetch faces:", error);
        return null;
    }
}

async function runDetection(faceMatcher) {
    if (!liveFeed.src || liveFeed.src.endsWith('/monitor') || liveFeed.naturalWidth === 0) return;
    
    const displaySize = { width: liveFeed.width, height: liveFeed.height };
    faceapi.matchDimensions(canvas, displaySize);

    const detections = await faceapi.detectAllFaces(liveFeed, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceDescriptors();
    const resizedDetections = faceapi.resizeResults(detections, displaySize);
    
    canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
    const currentFacesOnScreen = new Set();
    
    resizedDetections.forEach(d => {
        const match = faceMatcher.findBestMatch(d.descriptor);
        const personName = match.label;
        if (personName !== 'unknown') currentFacesOnScreen.add(personName);
        
        const drawBox = new faceapi.draw.DrawBox(d.detection.box, { label: personName });
        drawBox.draw(canvas);
        if (showPointsToggle.checked) faceapi.draw.drawFaceLandmarks(canvas, d);
        
        if (personName !== 'unknown' && !notifiedNames.has(personName)) {
            const personData = faceDataMap.get(personName);
            if (personData) {
                addLogEntry({ name: personName, action: personData.action });
                notifiedNames.add(personName);
            }
        }
    });

    notifiedNames.forEach(name => {
        if (!currentFacesOnScreen.has(name)) notifiedNames.delete(name);
    });
}

async function fetchAndDisplayFaces() {
    try {
        const response = await fetch('/faces');
        const faces = await response.json();
        faceList.innerHTML = '';
        if (faces.length === 0) {
            faceList.innerHTML = '<li>No people registered yet.</li>';
        } else {
            faces.forEach(face => {
                const listItem = document.createElement('li');
                listItem.innerHTML = `
                    <span>${face.name} (Action: ${face.action})</span>
                    <button class="delete-btn" data-id="${face._id}">Delete</button>
                `;
                faceList.appendChild(listItem);
            });
        }
    } catch (error) {
        console.error('Error fetching faces:', error);
        faceList.innerHTML = '<li>Error loading faces.</li>';
    }
}

faceList.addEventListener('click', async (event) => {
    if (event.target.classList.contains('delete-btn')) {
        const faceId = event.target.getAttribute('data-id');
        if (confirm('Are you sure you want to delete this person?')) {
            try {
                await fetch(`/delete/${faceId}`, { method: 'DELETE' });
                await fetchAndDisplayFaces();
                await startDetection();
            } catch (error) {
                console.error('Error deleting face:', error);
            }
        }
    }
});

function addLogEntry(logData, sendToServer = true) {
    const logEntry = document.createElement('div');
    logEntry.classList.add('log-entry', `log-${logData.action}`);
    const timestamp = new Date(logData.timestamp || Date.now());
    const istTime = timestamp.toLocaleString('en-IN', { timeStyle: 'medium', hour12: false, timeZone: 'Asia/Kolkata' });
    logEntry.innerHTML = `<strong>${logData.name}</strong> [${logData.action.toUpperCase()}]<br><small>${istTime}</small>`;
    logPanel.prepend(logEntry);
    if (logPanel.children.length > 50) logPanel.lastChild.remove();
    if (sendToServer) {
        fetch('/log', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(logData)
        }).catch(err => console.error('Failed to send log to server:', err));
    }
}

async function loadInitialLogs() {
    try {
        const response = await fetch('/logs');
        const logs = await response.json();
        logs.forEach(log => addLogEntry(log, false));
    } catch (error) {
        console.error('Failed to load initial logs:', error);
    }
}

async function fetchAndDisplaySettings() {
    try {
        const response = await fetch('/settings');
        const settings = await response.json();
        alertThresholdInput.value = settings.alertThreshold;
    } catch (error) {
        console.error('Error fetching settings:', error);
    }
}

saveSettingsBtn.addEventListener('click', async () => {
    const newThreshold = alertThresholdInput.value;
    await fetch('/settings', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ newThreshold })
    });
    alert('Settings saved!');
});

downloadDataBtn.addEventListener('click', async () => {
    const response = await fetch('/faces');
    const faces = await response.json();
    const dataStr = JSON.stringify(faces.map(f => ({ name: f.name, descriptor: f.descriptor, action: f.action })), null, 2);
    const link = document.createElement('a');
    link.href = URL.createObjectURL(new Blob([dataStr], { type: 'application/json' }));
    link.download = 'face_data_export.json';
    link.click();
    URL.revokeObjectURL(link.href);
});

importDataInput.addEventListener('change', (event) => {
    const file = event.target.files[0];
    if (!file) return;
    const reader = new FileReader();
    reader.onload = async (e) => {
        if (!confirm('This will replace all current data. Are you sure?')) return;
        try {
            const faces = JSON.parse(e.target.result);
            await fetch('/import', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ faces })
            });
            alert('Data imported!');
            await fetchAndDisplayFaces();
            await startDetection();
        } catch {
            alert('Invalid JSON file or import error.');
        }
    };
    reader.readAsText(file);
});


async function startDetection() {
    if (detectionInterval) clearInterval(detectionInterval);
    loader.innerText = 'Loading Registered Faces...';
    loader.style.display = 'block';

    const labeledFaceDescriptors = await getLabeledFaceDescriptions();
    
    if (!labeledFaceDescriptors) {
        loader.innerText = 'No faces registered. Please register a face.';
        setTimeout(() => {
            if (loader.innerText === 'No faces registered. Please register a face.') {
                loader.style.display = 'none';
            }
        }, 3000);
        return;
    }

    const faceMatcher = new faceapi.FaceMatcher(labeledFaceDescriptors, 0.55);
    loader.style.display = 'none';
    
    detectionInterval = setInterval(() => runDetection(faceMatcher), 500);
}

async function initialize() {
    try {
        await loadModels();
        setupSocketListeners();
        monitorContainer.style.display = 'block';
        
        await Promise.all([
            fetchAndDisplayFaces(),
            loadInitialLogs(),
            fetchAndDisplaySettings()
        ]);
        
        await startDetection();
    } catch (error) {
        console.error("Initialization failed:", error);
        loader.innerText = "Error during startup. Please refresh.";
    }
}

initialize();